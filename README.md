# -homework2
谢万皓 2223315786 15867115610

# 计算机视觉代码结构分析 (Code Structure Analysis)

该项目包含四个核心视觉算法的实现。以下是针对每个文件的代码逻辑与模块化结构的详细剖析。

## 1. Sobel 边缘检测 (`sobel.py`)

该脚本采用了 **“工具函数 + 主流程脚本”** 的结构。核心在于手动实现了卷积操作，而非直接调用库函数。

* **依赖库**: `numpy` (矩阵运算), `cv2` (图像IO), `matplotlib` (绘图)。
* **代码模块拆解**:
    * **自定义卷积工具 (`convolve2d`)**:
        * **输入**: 原始图像、卷积核。
        * **逻辑**:
            1.  **核翻转**: 上下左右翻转卷积核（符合严格的卷积定义）。
            2.  **边界填充**: 使用 `reflect` 模式对图像进行 Padding，防止尺寸缩小。
            3.  **滑动窗口**: 双重循环遍历像素，计算局部区域与核的点积之和。
    * **核定义**:
        * 定义了标准的 $3 \times 3$ Sobel X 和 Sobel Y 算子。
* **主执行流程**:
    1.  **读取**: 加载灰度图像。
    2.  **计算**: 分别调用 `convolve2d` 计算 $G_x$ 和 $G_y$。
    3.  **合成**: 计算梯度幅值与方向:
        * $$\text{Magnitude} = \sqrt{G_x^2 + G_y^2}$$
        * $$\text{Direction} = \arctan2(G_y, G_x)$$
    4.  **归一化**: 辅助函数 `normalize` 将数据映射回 0-255 范围以便显示。
    5.  **可视化**: 使用 Matplotlib 展示 6 张子图（原图、分量梯度、幅值、方向等）。

## 2. Canny 边缘检测 (`canny.py`)

该脚本采用了 **“高度模块化/流水线”** 的结构。每个 Canny 步骤被封装为独立的函数，最后由一个主函数串联。

* **依赖库**: `cv2`, `numpy`, `matplotlib`。
* **代码模块拆解**:
    * **降噪模块 (`gaussian_kernel`, `convolve2d`)**:
        * 动态生成指定尺寸和 $\sigma$ 的高斯核，并复用自定义的卷积函数进行平滑处理。
    * **梯度计算模块 (`compute_gradient`)**:
        * 内部定义 Sobel 算子，调用卷积函数，返回 $I_x, I_y$、梯度幅值和方向。
    * **非极大值抑制模块 (`non_max_suppression`)**:
        * **逻辑**: 遍历图像内部像素，根据梯度角度（量化为 0°, 45°, 90°, 135° 四个方向）比较当前像素与沿梯度方向邻域像素的幅值。若非最大，则抑制为 0。
    * **双阈值与滞后比较模块 (`double_threshold_and_hysteresis`)**:
        * **阈值分类**: 根据 `high_ratio` 和 `low_ratio` 将像素标记为强边缘（255）或弱边缘（75）。
        * **边缘连接**: 遍历弱边缘点，检查其 8 邻域内是否存在强边缘。若存在则保留（置为强边缘），否则抑制。
* **主控函数 (`manual_canny`)**:
    * 串联上述所有步骤，并统一处理图像读取、异常检查和最终的多图可视化。

## 3. Harris 角点检测 (`harris.py`)

该脚本采用了 **“线性脚本 (Procedural Script)”** 结构。没有封装复杂的中间函数，而是按照算法数学公式顺序直观地编写。

* **依赖库**: `cv2`, `numpy`, `matplotlib`。
* **代码逻辑流程**:
    1.  **预处理**: 读取图像并转为灰度浮点型 (`float32`)。
    2.  **梯度计算**: 使用 OpenCV 内置的 `cv2.Sobel` 计算 $I_x$ 和 $I_y$（此处未手动实现卷积）。
    3.  **结构张量构建 (M矩阵)**:
        * 计算二阶导数分量: $I_x^2, I_y^2, I_{xy}$。
        * **窗口加权**: 对上述分量分别应用高斯滤波 (`cv2.GaussianBlur`)，相当于对结构张量窗口内的值求和加权。
    4.  **角点响应计算 (R值)**:
        * 应用 Harris 公式（其中 $k=0.04$）:
            $$R = (I_x^2 \cdot I_y^2 - I_{xy}^2) - k \cdot (I_x^2 + I_y^2)^2$$
    5.  **后处理**:
        * 归一化 $R$ 值用于显示。
        * **阈值筛选**: 设定阈值（如最大值的 1%），筛选出角点坐标。
    6.  **可视化**: 在原图上标记红点并展示结果。

## 4. 直方图均衡化 (`image_normalization.py`)

该脚本同样采用了 **“线性脚本”** 结构，侧重于统计学计算。

* **依赖库**: `cv2`, `numpy`, `matplotlib`。
* **代码逻辑流程**:
    1.  **统计**: 使用 `np.histogram` 计算原始灰度图的直方图。
    2.  **CDF 计算**:
        * 使用 `cumsum()` 计算累积分布函数。
        * 归一化 CDF，将其映射到图像像素总数范围。
    3.  **均衡化映射**:
        * **Mask 处理**: 使用 NumPy 的掩码数组 (`np.ma.masked_equal`) 忽略 0 值，防止除零错误或计算偏差。
        * **线性拉伸**: 将 CDF 值线性映射到 $[0, 255]$ 区间。
        * **索引映射**: 利用 NumPy 的高级索引功能 (`cdf_final[img]`)，直接将原图的像素值作为索引，替换为均衡化后的新值。
    4.  **对比展示**: 创建 $2 \times 2$ 的图表，对比处理前后的图像及其对应的直方图分布。
